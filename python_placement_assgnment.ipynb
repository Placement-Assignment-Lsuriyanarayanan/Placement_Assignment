{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7d9862",
   "metadata": {},
   "source": [
    "## Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "229af942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text [q-> quit]i am a student of ineuron great ineuron\n",
      "The lengthiest word of high occurence words length is =7 and the words are =['ineuron']\n",
      "Enter a text [q-> quit]i am a student of ineuron great ineuron student\n",
      "The lengthiest word of high occurence words length is =7 and the words are =['student', 'ineuron']\n",
      "Enter a text [q-> quit]q\n"
     ]
    }
   ],
   "source": [
    "def get_high_occurence_word(text):\n",
    "    \n",
    "    #split the text into words\n",
    "    words=text.split(\" \")\n",
    "    words_occurence_count={} # create a dictionary to hold words and their no of occurence\n",
    "    len_high_occurence_words={}\n",
    "    highest_len=0\n",
    "    \n",
    "    #assign words and their no of occurence to the above dictionary \n",
    "    \n",
    "    for word in words:\n",
    "        if word in words_occurence_count:\n",
    "            words_occurence_count[word]+=1\n",
    "        else:\n",
    "            words_occurence_count[word]=1\n",
    "            \n",
    "    high_occurence=max(words_occurence_count.values()) #highest no of  occurence of words\n",
    "    high_occurence_words=[word for word,occurence in words_occurence_count.items() if occurence==high_occurence]\n",
    "\n",
    "    \n",
    "    for word in high_occurence_words:       \n",
    "            len_high_occurence_words[word]=len(word)\n",
    "        \n",
    "    #print(len_high_occurence_words.values())\n",
    "    \n",
    "    highest_len=max(len_high_occurence_words.values())\n",
    "    \n",
    "            \n",
    "    return (highest_len,high_occurence_words)\n",
    "                             \n",
    "\n",
    "                    \n",
    "                             \n",
    "while (True):\n",
    "    text=input(\"Enter a text [q-> quit]\")\n",
    "    if text in [\"q\",\"Q\"]:\n",
    "        break\n",
    "    else:\n",
    "        result1,result2=get_high_occurence_word(text)\n",
    "        print(f\"The lengthiest word of high occurence words length is ={result1} and the words are ={result2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3931161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab695b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_occurence_word(text):\n",
    "    \n",
    "    #split the text into words\n",
    "    words=text.split(\" \")\n",
    "    words_occurence_count={} # create a dictionary to hold words and their no of occurence\n",
    "    \n",
    "    #assign words and their no of occurence to the above dictionary \n",
    "    \n",
    "    for word in words:\n",
    "        if word in words_occurence_count:\n",
    "            words_occurence_count[word]+=1\n",
    "        else:\n",
    "            words_occurence_count[word]=1\n",
    "            \n",
    "    high_occurence=max(words_occurence_count.values()) #highest no of  occurence of words\n",
    "            \n",
    "    \n",
    "    for key,value in words_occurence_count.items():\n",
    "        if value==high_occurence:\n",
    "            highest_len_words.append(key)\n",
    "            \n",
    "    return (highest_len,highest_len_words)\n",
    "                             \n",
    "\n",
    "                    \n",
    "                             \n",
    "while (True):\n",
    "    text=input(\"Enter a text [q-> quit]\")\n",
    "    if text in [\"q\",\"Q\"]:\n",
    "        break\n",
    "    else:\n",
    "        result1,result2=get_high_occurence_word(text)\n",
    "        print(result1,result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdca0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def create_excel(link):\n",
    "    # Fetch JSON data from the URL\n",
    "    response = requests.get(link)\n",
    "    data = response.json()\n",
    "    pokemon_list = data[\"pokemon\"]\n",
    "    #print(pokemon_list)\n",
    "    # Iterate over each Pok√©mon and extract relevant information\n",
    "    structured_data = []\n",
    "    for pokemon in pokemon_list:\n",
    "        if pokemon.get(\"candy_count\") and pokemon.get(\"next_evolution\"):\n",
    "            pokemon_data = {\n",
    "                \"name\": pokemon[\"name\"],\n",
    "                \"type\": pokemon[\"type\"],\n",
    "                \"height\":pokemon[\"height\"],\n",
    "                \"weight\":pokemon[\"weight\"],\n",
    "                \"candy\":pokemon[\"candy\"],\n",
    "                \"candy_count\":pokemon[\"candy_count\"],\n",
    "                \"egg\":pokemon[\"egg\"],\n",
    "                \"spawn_chance\":pokemon[\"spawn_chance\"],\n",
    "                \"avg_spawns\":pokemon[\"avg_spawns\"],\n",
    "                \"spawn_time\":pokemon[\"spawn_time\"],\n",
    "                \"multipliers\":pokemon[\"multipliers\"],\n",
    "                \"weakness\":pokemon[\"weaknesses\"],\n",
    "                \"next_evolution\":pokemon[\"next_evolution\"]\n",
    "                }\n",
    "        else:\n",
    "            pokemon_data = {\n",
    "                \"name\": pokemon[\"name\"],\n",
    "                \"type\": pokemon[\"type\"],\n",
    "                \"height\":pokemon[\"height\"],\n",
    "                \"weight\":pokemon[\"weight\"],\n",
    "                \"candy\":pokemon[\"candy\"],\n",
    "                \"candy_count\":0,\n",
    "                \"egg\":pokemon[\"egg\"],\n",
    "                \"spawn_chance\":pokemon[\"spawn_chance\"],\n",
    "                \"avg_spawns\":pokemon[\"avg_spawns\"],\n",
    "                \"spawn_time\":pokemon[\"spawn_time\"],\n",
    "                \"multipliers\":pokemon[\"multipliers\"],\n",
    "                \"weakness\":pokemon[\"weaknesses\"],\n",
    "                \"next_evolution\":[{'num': '', 'name': ''}]\n",
    "                }\n",
    "        structured_data.append(pokemon_data)\n",
    "    df=pd.DataFrame(structured_data)\n",
    "    df = df.explode('next_evolution')\n",
    "    df = df.explode('type')\n",
    "    df = df.explode('multipliers')\n",
    "    df = df.explode('weakness')\n",
    "    df_flattened = pd.concat([df.drop('next_evolution', axis=1), df['next_evolution'].apply(pd.Series)], axis=1)\n",
    "    df_flattened=df_flattened.reset_index(drop=True)\n",
    "    df_flattened.drop_duplicates()\n",
    "    df_flattened.to_excel(\"flat_pokemon.xlsx\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "create_excel(\"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285cbf0",
   "metadata": {},
   "source": [
    "## Question 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c0af754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Flatten_csv(link):\n",
    "    # Fetch JSON data from the URL\n",
    "    response = requests.get(link)\n",
    "    data = response.json()\n",
    "    #print(data)\n",
    "    df=pd.DataFrame(data)\n",
    "    #df=df.explode(\"geolocation\")\n",
    "    df_flattened = pd.concat([df.drop('geolocation', axis=1), df['geolocation'].apply(pd.Series)], axis=1)\n",
    "    df_flattened[[\"Year\",\"month\",\"date\"]]=df_flattened[\"year\"].str.split(\"-\",2,expand=True)\n",
    "    df_flattened[[\"date\",\"minutes\",\"seconds\"]]=df_flattened[\"date\"].str.split(\":\",2,expand=True)\n",
    "    df_flattened[[\"seconds\",\"nano_seconds\"]]=df_flattened[\"seconds\"].str.split(\".\",1,expand=True)\n",
    "    df_flattened[[\"date\",\"Hours\"]]=df_flattened[\"date\"].str.split(\"T\",1,expand=True)\n",
    "    df_flattened[[\"longitude\",\"latitude\"]] = df_flattened['coordinates'].apply(lambda x: pd.Series(x))\n",
    "    df_flattened.drop(columns=[\"coordinates\",\"year\",\":@computed_region_cbhk_fwbd\",\":@computed_region_nnqa_25f4\",0],inplace=True)\n",
    "    df_flattened.to_csv(\"flat_csv.csv\",index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "Flatten_csv(\"https://data.nasa.gov/resource/y77d-th95.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db500c05",
   "metadata": {},
   "source": [
    "## Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d32052b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class CreateExcel:\n",
    "    \n",
    "    def __init__(self,filepath):\n",
    "        self.filepath=filepath\n",
    "        \n",
    "    def create_excel(self):\n",
    "        # Fetch JSON data from the URL\n",
    "        response = requests.get(self.filepath)\n",
    "        data = response.json()\n",
    "        pokemon_list = data[\"pokemon\"]\n",
    "        #print(len(pokemon_list))\n",
    "        df=pd.DataFrame(pokemon_list)\n",
    "        #print(df.size)\n",
    "        #print(df.shape)\n",
    "        df = df.explode('next_evolution')\n",
    "        df = df.explode('prev_evolution')\n",
    "        df = df.explode('type')\n",
    "        df = df.explode('multipliers')\n",
    "        df = df.explode('weaknesses')\n",
    "        df[[\"next_evolution_num\",\"next_evolution_name\",0]]=df['next_evolution'].apply(pd.Series)\n",
    "        df[[0,\"prev_evolution_num\",\"prev_evolution_name\"]]=df['prev_evolution'].apply(pd.Series)\n",
    "        df=df.drop(columns=['next_evolution','prev_evolution',0], axis=1)\n",
    "        #df_flattened = pd.concat([df.drop('next_evolution', axis=1), df[[\"next_num\",\"next_name\"]]], axis=1)\n",
    "        #df_flattened = pd.concat([df.drop('prev_evolution', axis=1), df['prev_evolution'].apply(pd.Series)], axis=1)\n",
    "        df=df.reset_index(drop=True)\n",
    "        #df_flattened.drop_duplicates()\n",
    "        df.to_excel(\"flat_pokemon_new.xlsx\")\n",
    "        #print(df.shape)\n",
    "        \n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "ce=CreateExcel(\"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\")\n",
    "ce.create_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7f9cc",
   "metadata": {},
   "source": [
    "## Question 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2da32d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                                url  \\\n",
      "0  869671  https://www.tvmaze.com/episodes/869671/westwor...   \n",
      "1  911201  https://www.tvmaze.com/episodes/911201/westwor...   \n",
      "2  911204  https://www.tvmaze.com/episodes/911204/westwor...   \n",
      "3  911205  https://www.tvmaze.com/episodes/911205/westwor...   \n",
      "4  927174  https://www.tvmaze.com/episodes/927174/westwor...   \n",
      "\n",
      "                name  season  number     type     airdate   airtime  runtime  \\\n",
      "0       The Original       1       1  regular  2016-10-02  09:00 PM       68   \n",
      "1           Chestnut       1       2  regular  2016-10-09  09:00 PM       60   \n",
      "2          The Stray       1       3  regular  2016-10-16  09:00 PM       60   \n",
      "3  Dissonance Theory       1       4  regular  2016-10-23  09:00 PM       60   \n",
      "4        Contrapasso       1       5  regular  2016-10-30  09:00 PM       60   \n",
      "\n",
      "                                             summary  average_rating  \\\n",
      "0  A woman named Dolores is a free spirit in the ...             8.0   \n",
      "1  Bernard suspects that someone is sabotaging th...             7.7   \n",
      "2  Bernard continues to investigate Dolores' supp...             7.6   \n",
      "3  While Dolores joins William and Logan on their...             7.9   \n",
      "4  Dolores takes the first step on her path of di...             8.0   \n",
      "\n",
      "                                   medium_image_link  \\\n",
      "0  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "1  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "2  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "3  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "4  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "\n",
      "                                 original_image_link  \n",
      "0  https://static.tvmaze.com/uploads/images/origi...  \n",
      "1  https://static.tvmaze.com/uploads/images/origi...  \n",
      "2  https://static.tvmaze.com/uploads/images/origi...  \n",
      "3  https://static.tvmaze.com/uploads/images/origi...  \n",
      "4  https://static.tvmaze.com/uploads/images/origi...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "class Data_cleaning:\n",
    "    def __init__(self,link):\n",
    "        self.link=link\n",
    "    \n",
    "    def cleaning(self):\n",
    "        response=requests.get(self.link)\n",
    "        data=response.json()\n",
    "        shows_list=data['_embedded']['episodes']\n",
    "        df=pd.DataFrame(shows_list)\n",
    "        df['average_rating']=df[\"rating\"].apply(pd.Series)\n",
    "        df[[\"medium_image_link\",\"original_image_link\"]]=df[\"image\"].apply(pd.Series)\n",
    "        df[\"summary\"]=df[\"summary\"].str.strip(\"12<p></p>\")\n",
    "        df[\"summary\"]=df[\"summary\"].str.rstrip(\"\\xa0<br />\\xa0\")\n",
    "        df.drop(columns=[\"rating\",\"image\",\"_links\",\"airstamp\"],inplace=True)\n",
    "        df['airtime'] = pd.to_datetime(df['airtime'], format='%H:%M').dt.strftime('%I:%M %p')\n",
    "        print(df.head())\n",
    "\n",
    "    \n",
    "dc=Data_cleaning(\"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\")\n",
    "dc.cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9bc1ed94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#for i in range(len(df[\"summary\"])):\n",
    " #   print(i,\"--->\",df['summary'][i],\"<---\")\n",
    "type(float(df['airtime'][0].split(\":\")[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96a00594",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1482564773.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[81], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    pd.tseries df['airtime']\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#pd.to_timedelta(df['airtime'])\n",
    "pd.tseries df['airtime']\n",
    "#pd.tseries(df['airtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3baad2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "     -------------------------------------- 112.2/112.2 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: webencodings in c:\\users\\dell\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from html5lib) (1.16.0)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a9f7eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mairtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_datetime'"
     ]
    }
   ],
   "source": [
    ".to_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14a3d5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "1     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "2     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "3     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "4     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "5     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "6     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "7     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "8     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "9     9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "10    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "11    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "12    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "13    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "14    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "15    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "16    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "17    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "18    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "19    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "20    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "21    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "22    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "23    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "24    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "25    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "26    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "27    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "28    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "29    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "30    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "31    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "32    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "33    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "34    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "35    9:0     0\\n1     0\\n2     0\\n3     0\\n4     0\\...\n",
       "Name: airtime, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airtime']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f90c0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_datetime(df['airtime']).dt.minute\n",
    "\n",
    "df['airtime'] = pd.to_datetime(df['airtime'], format='%H:%M').dt.strftime('%I:%M %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74ada256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     09:00 PM\n",
       "1     09:00 PM\n",
       "2     09:00 PM\n",
       "3     09:00 PM\n",
       "4     09:00 PM\n",
       "5     09:00 PM\n",
       "6     09:00 PM\n",
       "7     09:00 PM\n",
       "8     09:00 PM\n",
       "9     09:00 PM\n",
       "10    09:00 PM\n",
       "11    09:00 PM\n",
       "12    09:00 PM\n",
       "13    09:00 PM\n",
       "14    09:00 PM\n",
       "15    09:00 PM\n",
       "16    09:00 PM\n",
       "17    09:00 PM\n",
       "18    09:00 PM\n",
       "19    09:00 PM\n",
       "20    09:00 PM\n",
       "21    09:00 PM\n",
       "22    09:00 PM\n",
       "23    09:00 PM\n",
       "24    09:00 PM\n",
       "25    09:00 PM\n",
       "26    09:00 PM\n",
       "27    09:00 PM\n",
       "28    09:00 PM\n",
       "29    09:00 PM\n",
       "30    09:00 PM\n",
       "31    09:00 PM\n",
       "32    09:00 PM\n",
       "33    09:00 PM\n",
       "34    09:00 PM\n",
       "35    09:00 PM\n",
       "Name: airtime, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airtime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0e71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a47121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c4394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ac45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
