{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7d9862",
   "metadata": {},
   "source": [
    "## Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "229af942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text [q-> quit]i am a student of ineuron great ineuron\n",
      "The lengthiest word of high occurence words length is =7 and the words are =['ineuron']\n",
      "Enter a text [q-> quit]i am a student of ineuron great ineuron student\n",
      "The lengthiest word of high occurence words length is =7 and the words are =['student', 'ineuron']\n",
      "Enter a text [q-> quit]q\n"
     ]
    }
   ],
   "source": [
    "def get_high_occurence_word(text):\n",
    "    \n",
    "    #split the text into words\n",
    "    words=text.split(\" \")\n",
    "    words_occurence_count={} # create a dictionary to hold words and their no of occurence\n",
    "    len_high_occurence_words={}\n",
    "    highest_len=0\n",
    "    \n",
    "    #assign words and their no of occurence to the above dictionary \n",
    "    \n",
    "    for word in words:\n",
    "        if word in words_occurence_count:\n",
    "            words_occurence_count[word]+=1\n",
    "        else:\n",
    "            words_occurence_count[word]=1\n",
    "            \n",
    "    high_occurence=max(words_occurence_count.values()) #highest no of  occurence of words\n",
    "    high_occurence_words=[word for word,occurence in words_occurence_count.items() if occurence==high_occurence]\n",
    "\n",
    "    \n",
    "    for word in high_occurence_words:       \n",
    "            len_high_occurence_words[word]=len(word)\n",
    "        \n",
    "    #print(len_high_occurence_words.values())\n",
    "    \n",
    "    highest_len=max(len_high_occurence_words.values())\n",
    "    \n",
    "            \n",
    "    return (highest_len,high_occurence_words)\n",
    "                             \n",
    "\n",
    "                    \n",
    "                             \n",
    "while (True):\n",
    "    text=input(\"Enter a text [q-> quit]\")\n",
    "    if text in [\"q\",\"Q\"]:\n",
    "        break\n",
    "    else:\n",
    "        result1,result2=get_high_occurence_word(text)\n",
    "        print(f\"The lengthiest word of high occurence words length is ={result1} and the words are ={result2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3931161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7285cbf0",
   "metadata": {},
   "source": [
    "## Question 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c0af754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def Flatten_csv(link):\n",
    "    # Fetch JSON data from the URL\n",
    "    response = requests.get(link)\n",
    "    data = response.json()\n",
    "    #print(data)\n",
    "    df=pd.DataFrame(data)\n",
    "    #df=df.explode(\"geolocation\")\n",
    "    df_flattened = pd.concat([df.drop('geolocation', axis=1), df['geolocation'].apply(pd.Series)], axis=1)\n",
    "    df_flattened[[\"Year\",\"month\",\"date\"]]=df_flattened[\"year\"].str.split(\"-\",2,expand=True)\n",
    "    df_flattened[[\"date\",\"minutes\",\"seconds\"]]=df_flattened[\"date\"].str.split(\":\",2,expand=True)\n",
    "    df_flattened[[\"seconds\",\"nano_seconds\"]]=df_flattened[\"seconds\"].str.split(\".\",1,expand=True)\n",
    "    df_flattened[[\"date\",\"Hours\"]]=df_flattened[\"date\"].str.split(\"T\",1,expand=True)\n",
    "    df_flattened[[\"longitude\",\"latitude\"]] = df_flattened['coordinates'].apply(lambda x: pd.Series(x))\n",
    "    df_flattened.drop(columns=[\"coordinates\",\"year\",\":@computed_region_cbhk_fwbd\",\":@computed_region_nnqa_25f4\",0],inplace=True)\n",
    "    df_flattened.to_csv(\"flat_csv.csv\",index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "Flatten_csv(\"https://data.nasa.gov/resource/y77d-th95.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db500c05",
   "metadata": {},
   "source": [
    "## Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d32052b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class CreateExcel:\n",
    "    \n",
    "    def __init__(self,filepath):\n",
    "        self.filepath=filepath\n",
    "        \n",
    "    def create_excel(self):\n",
    "        # Fetch JSON data from the URL\n",
    "        response = requests.get(self.filepath)\n",
    "        data = response.json()\n",
    "        pokemon_list = data[\"pokemon\"]\n",
    "        #print(len(pokemon_list))\n",
    "        df=pd.DataFrame(pokemon_list)\n",
    "        #print(df.size)\n",
    "        #print(df.shape)\n",
    "        df = df.explode('next_evolution')\n",
    "        df = df.explode('prev_evolution')\n",
    "        df = df.explode('type')\n",
    "        df = df.explode('multipliers')\n",
    "        df = df.explode('weaknesses')\n",
    "        df[[\"next_evolution_num\",\"next_evolution_name\",0]]=df['next_evolution'].apply(pd.Series)\n",
    "        df[[0,\"prev_evolution_num\",\"prev_evolution_name\"]]=df['prev_evolution'].apply(pd.Series)\n",
    "        df=df.drop(columns=['next_evolution','prev_evolution',0], axis=1)\n",
    "        #df_flattened = pd.concat([df.drop('next_evolution', axis=1), df[[\"next_num\",\"next_name\"]]], axis=1)\n",
    "        #df_flattened = pd.concat([df.drop('prev_evolution', axis=1), df['prev_evolution'].apply(pd.Series)], axis=1)\n",
    "        df=df.reset_index(drop=True)\n",
    "        #df_flattened.drop_duplicates()\n",
    "        df.to_excel(\"flat_pokemon_new.xlsx\")\n",
    "        #print(df.shape)\n",
    "        \n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "ce=CreateExcel(\"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\")\n",
    "ce.create_excel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7f9cc",
   "metadata": {},
   "source": [
    "## Question 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2da32d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                                url  \\\n",
      "0  869671  https://www.tvmaze.com/episodes/869671/westwor...   \n",
      "1  911201  https://www.tvmaze.com/episodes/911201/westwor...   \n",
      "2  911204  https://www.tvmaze.com/episodes/911204/westwor...   \n",
      "3  911205  https://www.tvmaze.com/episodes/911205/westwor...   \n",
      "4  927174  https://www.tvmaze.com/episodes/927174/westwor...   \n",
      "\n",
      "                name  season  number     type     airdate   airtime  runtime  \\\n",
      "0       The Original       1       1  regular  2016-10-02  09:00 PM       68   \n",
      "1           Chestnut       1       2  regular  2016-10-09  09:00 PM       60   \n",
      "2          The Stray       1       3  regular  2016-10-16  09:00 PM       60   \n",
      "3  Dissonance Theory       1       4  regular  2016-10-23  09:00 PM       60   \n",
      "4        Contrapasso       1       5  regular  2016-10-30  09:00 PM       60   \n",
      "\n",
      "                                             summary  average_rating  \\\n",
      "0  A woman named Dolores is a free spirit in the ...             8.0   \n",
      "1  Bernard suspects that someone is sabotaging th...             7.7   \n",
      "2  Bernard continues to investigate Dolores' supp...             7.6   \n",
      "3  While Dolores joins William and Logan on their...             7.9   \n",
      "4  Dolores takes the first step on her path of di...             8.0   \n",
      "\n",
      "                                   medium_image_link  \\\n",
      "0  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "1  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "2  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "3  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "4  https://static.tvmaze.com/uploads/images/mediu...   \n",
      "\n",
      "                                 original_image_link  \n",
      "0  https://static.tvmaze.com/uploads/images/origi...  \n",
      "1  https://static.tvmaze.com/uploads/images/origi...  \n",
      "2  https://static.tvmaze.com/uploads/images/origi...  \n",
      "3  https://static.tvmaze.com/uploads/images/origi...  \n",
      "4  https://static.tvmaze.com/uploads/images/origi...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "class Data_cleaning:\n",
    "    def __init__(self,link):\n",
    "        self.link=link\n",
    "    \n",
    "    def cleaning(self):\n",
    "        response=requests.get(self.link)\n",
    "        data=response.json()\n",
    "        shows_list=data['_embedded']['episodes']\n",
    "        df=pd.DataFrame(shows_list)\n",
    "        df['average_rating']=df[\"rating\"].apply(pd.Series)\n",
    "        df[[\"medium_image_link\",\"original_image_link\"]]=df[\"image\"].apply(pd.Series)\n",
    "        df[\"summary\"]=df[\"summary\"].str.strip(\"12<p></p>\")\n",
    "        df[\"summary\"]=df[\"summary\"].str.rstrip(\"\\xa0<br />\\xa0\")\n",
    "        df.drop(columns=[\"rating\",\"image\",\"_links\",\"airstamp\"],inplace=True)\n",
    "        df['airtime'] = pd.to_datetime(df['airtime'], format='%H:%M').dt.strftime('%I:%M %p')\n",
    "        print(df.head())\n",
    "\n",
    "    \n",
    "dc=Data_cleaning(\"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\")\n",
    "dc.cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ac45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
